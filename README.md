# slt-demo
**Sign Language Translation - Gradio web app for Video to Text**

This demo is a proof of concept for the translation system of ASL. It uses YoloV8, MediaPipe and T5 in the backend, trained on the YoutubeASL dataset by the CV team at UWB. See [T5_for_SLT](https://github.com/zeleznyt/T5_for_SLT) and [PoseEstimation](https://github.com/JSALT2024/PoseEstimation).

## Find the demo at [HuggingFace spaces](https://huggingface.co/spaces/VaJavorek/slt-demo)

## How to run locally

 1. Clone repository
 ```commandline
git clone https://github.com/JSALT2024/slt-demo.git
```
    

 2. Install dependencies

```commandline
pip install -r requirements.txt
```

 3. Run the demo
 ```commandline
python app.py
```
 4. Open http://127.0.0.1:7860/

 5. You are good to go! Upload any video or use your webcam ðŸ“·


## Code structure
```
slt-demo/
â”œâ”€â”€ backend.py
â”œâ”€â”€ predict_pose.py
â”œâ”€â”€ sltGradio.py
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ pose/
â”‚   â”‚   â””â”€â”€ [pose model files]
â”‚   â””â”€â”€ t5-v1_1-base/
â”‚       â””â”€â”€ [T5 model files]
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ predict_config_demo.yaml
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ generic_sl_dataset.py
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ configuration_t5.py
â”‚   â””â”€â”€ modeling_t5.py
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ translation.py
â””â”€â”€ video/
    â””â”€â”€ [example videos]
```